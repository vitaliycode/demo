"""
Gradio UI –¥–ª—è SmolVLM Demo.
–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è VQA –∏ OCR.
"""
import gradio as gr
from PIL import Image
from typing import Optional, List, Tuple
import time
from pathlib import Path

from app.config import settings
from app.model_manager import ModelManager


def create_gradio_interface(model_manager: ModelManager):
    """
    –°–æ–∑–¥–∞–Ω–∏–µ Gradio –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ –¥–ª—è SmolVLM Demo.
    
    Args:
        model_manager: –≠–∫–∑–µ–º–ø–ª—è—Ä ModelManager
        
    Returns:
        Gradio Blocks –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
    """
    
    # –•—Ä–∞–Ω–∏–ª–∏—â–µ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞ –¥–ª—è –∫–∞–∂–¥–æ–π —Å–µ—Å—Å–∏–∏
    _chat_sessions = {}
    
    def chat_vqa(
        image: Optional[Image.Image],
        message: str,
        history: Optional[List] = None
    ) -> Tuple[List, str, Optional[str]]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ VQA —á–∞—Ç –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è.
        
        Args:
            image: PIL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            message: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            history: –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ –∏–∑ (–æ–±–Ω–æ–≤–ª–µ–Ω–Ω–∞—è_–∏—Å—Ç–æ—Ä–∏—è, –æ—á–∏—â–µ–Ω–Ω—ã–π_–≤–≤–æ–¥, —Ñ–∞–π–ª_–¥–ª—è_—Å–∫–∞—á–∏–≤–∞–Ω–∏—è)
        """
        if history is None:
            history = []
        
        message = (message or "").strip()
        
        if not message:
            return history, "", None
        
        if not image:
            history.append({
                "role": "assistant",
                "content": "‚ö†Ô∏è Please upload an image first."
            })
            return history, "", None
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        history.append({"role": "user", "content": message})
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ placeholder –¥–ª—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        history.append({"role": "assistant", "content": "üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞..."})
        
        try:
            # –ó–∞–ø—É—Å–∫ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞
            start_time = time.time()
            answer = model_manager.vqa_inference(image, message)
            processing_time = time.time() - start_time
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ —Å –æ—Ç–≤–µ—Ç–æ–º
            history[-1]["content"] = answer
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª
            timestamp = int(time.time())
            out_dir = Path("outputs/chat")
            out_dir.mkdir(parents=True, exist_ok=True)
            out_path = out_dir / f"chat_result_{timestamp}.txt"
            
            with open(out_path, "w", encoding="utf-8") as f:
                f.write(f"Question: {message}\n\n")
                f.write(f"Answer: {answer}\n\n")
                f.write(f"Processing time: {processing_time:.2f}s\n")
            
            return history, "", str(out_path)
        
        except Exception as e:
            history[-1]["content"] = f"‚ùå Error: {str(e)}"
            return history, "", None
    
    def run_ocr(image: Optional[Image.Image]) -> Tuple[str, Optional[str]]:
        """
        –ó–∞–ø—É—Å–∫ OCR –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.
        
        Args:
            image: PIL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ –∏–∑ (–∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π_—Ç–µ–∫—Å—Ç, —Ñ–∞–π–ª_–¥–ª—è_—Å–∫–∞—á–∏–≤–∞–Ω–∏—è)
        """
        if not image:
            return "‚ö†Ô∏è Please upload an image with text.", None
        
        try:
            # –ó–∞–ø—É—Å–∫ OCR
            start_time = time.time()
            text = model_manager.ocr_inference(image)
            processing_time = time.time() - start_time
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–∞–π–ª
            timestamp = int(time.time())
            out_dir = Path("outputs/ocr")
            out_dir.mkdir(parents=True, exist_ok=True)
            out_path = out_dir / f"ocr_result_{timestamp}.txt"
            
            with open(out_path, "w", encoding="utf-8") as f:
                f.write(text)
                f.write(f"\n\n--- Processing time: {processing_time:.2f}s ---\n")
            
            return text, str(out_path)
        
        except Exception as e:
            return f"‚ùå Error: {str(e)}", None
    
    def generate_caption(image: Optional[Image.Image]) -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–¥–ø–∏—Å–∏ –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é.
        
        Args:
            image: PIL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            
        Returns:
            –¢–µ–∫—Å—Ç –ø–æ–¥–ø–∏—Å–∏
        """
        if not image:
            return "‚ö†Ô∏è Please upload an image."
        
        try:
            caption = model_manager.caption_inference(image)
            return caption
        except Exception as e:
            return f"‚ùå Error: {str(e)}"
    
    # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π CSS
    custom_css = """
    .gradio-container {
        max-width: 1400px !important;
        margin: 0 auto;
    }
    
    .header-text {
        text-align: center;
        padding: 20px;
    }
    
    .tab-content {
        padding: 15px;
    }
    
    .card {
        border-radius: 10px;
        border: 1px solid var(--border-color-primary);
        padding: 15px;
        background: var(--background-fill-secondary);
    }
    
    .info-box {
        background: var(--background-fill-secondary);
        border-radius: 8px;
        padding: 10px;
        margin: 10px 0;
        font-size: 0.9em;
    }
    """
    
    # –°–æ–∑–¥–∞–Ω–∏–µ Gradio –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
    with gr.Blocks(
        title=f"{settings.APP_NAME}",
        theme=gr.themes.Soft(),
        css=custom_css
    ) as demo:
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        gr.Markdown(
            f"""
            <div class="header-text">
            
            # ü§ñ {settings.APP_NAME}
            
            **Model:** `{settings.MODEL_NAME}`  
            **Device:** `{settings.DEVICE}` | **Version:** `{settings.VERSION}`
            
            Multimodal Vision-Language Model for VQA, OCR, and Image Captioning
            
            </div>
            """
        )
        
        # –í–∫–ª–∞–¥–∫–∞ VQA
        with gr.Tab("üí¨ Visual Question Answering"):
            gr.Markdown(
                """
                <div class="info-box">
                üì∏ Upload an image and ask questions about it. The model will analyze the image and provide detailed answers.
                </div>
                """
            )
            
            with gr.Row(equal_height=True):
                with gr.Column(scale=1):
                    vqa_image = gr.Image(
                        label="Upload Image",
                        type="pil",
                        height=500
                    )
                
                with gr.Column(scale=1):
                    vqa_chatbot = gr.Chatbot(
                        label="Conversation",
                        height=500,
                        type="messages"
                    )
            
            with gr.Row():
                vqa_input = gr.Textbox(
                    label="Your Question",
                    placeholder="Ask anything about the image...",
                    lines=2
                )
            
            with gr.Row():
                vqa_submit = gr.Button("üöÄ Send", variant="primary", scale=2)
                vqa_clear = gr.Button("üóëÔ∏è Clear Chat", scale=1)
            
            with gr.Row():
                vqa_file = gr.File(label="üíæ Download Last Answer")
            
            # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ VQA
            vqa_submit.click(
                fn=chat_vqa,
                inputs=[vqa_image, vqa_input, vqa_chatbot],
                outputs=[vqa_chatbot, vqa_input, vqa_file]
            )
            
            vqa_input.submit(
                fn=chat_vqa,
                inputs=[vqa_image, vqa_input, vqa_chatbot],
                outputs=[vqa_chatbot, vqa_input, vqa_file]
            )
            
            vqa_clear.click(
                lambda: ([], None),
                outputs=[vqa_chatbot, vqa_file]
            )
        
        # –í–∫–ª–∞–¥–∫–∞ OCR
        with gr.Tab("üìù OCR (Text Recognition)"):
            gr.Markdown(
                """
                <div class="info-box">
                üìÑ Extract text from images. Upload an image containing text and get the recognized text output.
                </div>
                """
            )
            
            with gr.Row(equal_height=True):
                with gr.Column(scale=1):
                    ocr_image = gr.Image(
                        label="Upload Image with Text",
                        type="pil",
                        height=500
                    )
                
                with gr.Column(scale=1):
                    ocr_output = gr.Textbox(
                        label="Extracted Text",
                        lines=20,
                        max_lines=30
                    )
            
            with gr.Row():
                ocr_button = gr.Button("üîç Extract Text", variant="primary")
            
            with gr.Row():
                ocr_file = gr.File(label="üíæ Download Result")
            
            # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ OCR
            ocr_button.click(
                fn=run_ocr,
                inputs=[ocr_image],
                outputs=[ocr_output, ocr_file]
            )
        
        # –í–∫–ª–∞–¥–∫–∞ Captioning
        with gr.Tab("üñºÔ∏è Image Captioning"):
            gr.Markdown(
                """
                <div class="info-box">
                ‚ú® Generate descriptive captions for your images automatically.
                </div>
                """
            )
            
            with gr.Row(equal_height=True):
                with gr.Column(scale=1):
                    caption_image = gr.Image(
                        label="Upload Image",
                        type="pil",
                        height=500
                    )
                
                with gr.Column(scale=1):
                    caption_output = gr.Textbox(
                        label="Generated Caption",
                        lines=10,
                        max_lines=15
                    )
            
            with gr.Row():
                caption_button = gr.Button("‚ú® Generate Caption", variant="primary")
            
            # –û–±—Ä–∞–±–æ—Ç—á–∏–∫ Caption
            caption_button.click(
                fn=generate_caption,
                inputs=[caption_image],
                outputs=[caption_output]
            )
        
        # –í–∫–ª–∞–¥–∫–∞ About
        with gr.Tab("‚ÑπÔ∏è About"):
            gr.Markdown(
                f"""
                ## About SmolVLM Demo
                
                This application demonstrates the capabilities of the **SmolVLM** multimodal vision-language model.
                
                ### Features
                
                - **Visual Question Answering (VQA)**: Ask questions about images and get intelligent answers
                - **Optical Character Recognition (OCR)**: Extract text from images
                - **Image Captioning**: Generate descriptive captions automatically
                - **Multi-turn Conversations**: Continue asking questions about the same image
                - **Export Results**: Download your results as text files
                
                ### Model Information
                
                - **Model Name**: `{settings.MODEL_NAME}`
                - **Model Size**: `{settings.MODEL_SIZE}`
                - **Device**: `{settings.DEVICE}`
                - **Max Tokens**: `{settings.MAX_NEW_TOKENS}`
                - **Temperature**: `{settings.TEMPERATURE}`
                
                ### API Access
                
                This application also provides a REST API. Visit [/docs](/docs) for API documentation.
                
                ### Limitations
                
                - Maximum image size: {settings.MAX_IMAGE_SIZE / (1024*1024):.0f} MB
                - Maximum image dimension: {settings.MAX_IMAGE_DIMENSION} pixels
                - Session timeout: {settings.SESSION_TIMEOUT} seconds
                
                ### Resources
                
                - [SmolVLM on HuggingFace](https://huggingface.co/HuggingFaceTB)
                - [Project Documentation](/docs)
                - [API Reference](/docs)
                """
            )
    
    return demo

