# SmolVLM Demo Environment Configuration

# Server Settings
HOST=0.0.0.0
PORT=8000
WORKERS=1
DEBUG=false

# Model Configuration
MODEL_SIZE=500M
# Available sizes: 256M, 500M
MODEL_NAME=HuggingFaceTB/SmolVLM2-500M-Video-Instruct

# Device Settings
DEVICE=cpu
# Options: cpu, cuda
TORCH_DTYPE=float32
# Options: float32 (CPU), float16, bfloat16 (GPU)

# HuggingFace Cache
HF_HOME=/data/hf-cache
TRANSFORMERS_CACHE=/data/hf-cache
HF_LOCAL_ONLY=0
# Set to 1 for offline mode (requires pre-downloaded model)

# Inference Settings
MAX_NEW_TOKENS=512
TEMPERATURE=0.7
REPETITION_PENALTY=1.2
INFERENCE_TIMEOUT=300

# Gradio UI
ENABLE_GRADIO=true
GRADIO_PORT=7860

# Image Limits
MAX_IMAGE_SIZE=10485760
# Max size in bytes (10MB)
MAX_IMAGE_DIMENSION=4096

# Session Management
SESSION_TIMEOUT=3600
# Timeout in seconds (1 hour)

